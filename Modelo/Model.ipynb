{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15fdae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d526f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Criação de uma SEED\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "def criar_seed(seed=SEED):\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed) # Controla aleatoriedade interna do interpretador Python\n",
    "  random.seed(seed) # Controla aleatoriedade da biblioteca random\n",
    "  np.random.seed(seed) # Controla aleatoriedade do NumPy\n",
    "  tf.random.set_seed(seed) # Controla aleatoriedade do TensorFlow (pesos, embaralhamento, etc)\n",
    "\n",
    "def setar_deterministico(seed=SEED): # Garantir que se obtenha os mesmos valores ao rodar o código novamente\n",
    "  criar_seed(seed=seed) # Setar as seeds\n",
    "  os.environ['TF_DETERMINISTIC_OPS'] = '1' # Força o TensorFlow a usar operações determinísticas\n",
    "  os.environ['TF_CUDNN_DETERMINISTIC'] = '1' # Força operações determinísticas específicas da GPU (cuDNN)\n",
    "  tf.config.threading.set_inter_op_parallelism_threads(1) # Limita o paralelismo entre operações a 1 thread\n",
    "  tf.config.threading.set_intra_op_parallelism_threads(1) # Limita o paralelismo dentro de cada operação a 1 thread\n",
    "\n",
    "setar_deterministico(SEED)  # Executa tudo acima com a seed escolhida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f81bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === usar dados salvos (sem baixar nada) ===\n",
    "import os, numpy as np, joblib\n",
    "\n",
    "# ajuste só esses dois conforme sua pasta/ativo\n",
    "TICKER   = \"BBDC4\"\n",
    "DATA_DIR = \"../Dados/Treinamento/BBDC4\"  # ex.: \"../Dados/Treinamento/ABEV3\" se estiver em outra pasta\n",
    "\n",
    "# caminhos\n",
    "pXtr = os.path.join(DATA_DIR, f\"X_train_{TICKER}.npy\")\n",
    "pYtr = os.path.join(DATA_DIR, f\"y_train_{TICKER}.npy\")\n",
    "pXte = os.path.join(DATA_DIR, f\"X_test_{TICKER}.npy\")\n",
    "pYte = os.path.join(DATA_DIR, f\"y_test_{TICKER}.npy\")\n",
    "pSc  = os.path.join(DATA_DIR, f\"scaler_{TICKER}.pkl\")\n",
    "\n",
    "# (opcional) se você salvou os y reais já desnormalizados\n",
    "pYtr_real = os.path.join(DATA_DIR, f\"y_real_train_{TICKER}.npy\")\n",
    "pYte_real = os.path.join(DATA_DIR, f\"y_real_{TICKER}.npy\")\n",
    "\n",
    "# carregamento\n",
    "X_train = np.load(pXtr)\n",
    "y_train = np.load(pYtr)\n",
    "X_test  = np.load(pXte)\n",
    "y_test  = np.load(pYte)\n",
    "\n",
    "scaler  = joblib.load(pSc)\n",
    "\n",
    "# shapes úteis\n",
    "n_timesteps = X_train.shape[1]\n",
    "n_features  = X_train.shape[2]\n",
    "\n",
    "# garante compatibilidade scaler <-> features\n",
    "if hasattr(scaler, \"n_features_in_\"):\n",
    "    assert scaler.n_features_in_ == n_features, (\n",
    "        f\"Scaler foi treinado com {scaler.n_features_in_} features, \"\n",
    "        f\"mas X_* tem {n_features}.\"\n",
    "    )\n",
    "\n",
    "print(\"OK: dados salvos carregados.\")\n",
    "print(\"X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "print(\"X_test :\", X_test.shape,  \"| y_test :\", y_test.shape)\n",
    "print(\"n_timesteps:\", n_timesteps, \"| n_features:\", n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d16514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === carrega y real desnormalizado se existir (facilita nos gráficos) ===\n",
    "y_real_train = None\n",
    "y_real_test  = None\n",
    "\n",
    "if os.path.exists(pYtr_real):\n",
    "    y_real_train = np.load(pYtr_real)\n",
    "if os.path.exists(pYte_real):\n",
    "    y_real_test  = np.load(pYte_real)\n",
    "\n",
    "if y_real_train is not None and y_real_test is not None:\n",
    "    print(\"OK: y_real_train/y_real_test carregados (desnormalizados).\")\n",
    "else:\n",
    "    print(\"Aviso: y_real_* não encontrados. Vamos desfazer a normalização com o scaler após o predict.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
